{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203c268a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhats missing?\\n-get the big grid search running\\n-fix the non start issue\\n-\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TDL\n",
    "\"\"\"\n",
    "Whats missing?\n",
    "-get the big grid search running\n",
    "-fix the non start issue\n",
    "-\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca23701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def evaluate_net(net, x, y):\n",
    "    predictions = net.predict(x, config[\"inference_steps\"])[0]\n",
    "    correct_count = len(x) - (np.sum(np.abs(y - predictions)) / 2)\n",
    "    performance = correct_count / len(x)\n",
    "    return (performance, net)\n",
    "\n",
    "def evaluate_performance_fast(population, x, y):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        performances = list(executor.map(evaluate_net, population, [x] * len(population), [y] * len(population)))\n",
    "\n",
    "    print(\"Evaluation done!\")\n",
    "\n",
    "    # Sort by best performance\n",
    "    performances.sort(key=lambda x: x[0], reverse=True)\n",
    "    return performances\n",
    "\n",
    "\n",
    "# Pseudo-code for the new version of the evaluate_performance function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad88aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from non_layered_neural_net import nlnn\n",
    "import tracemalloc\n",
    "import functools\n",
    "from typing import Callable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa59bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage_decorator(func: Callable):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tracemalloc.start()\n",
    "        before_memory = get_memory_usage()\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        after_memory = get_memory_usage()\n",
    "        tracemalloc.stop()\n",
    "\n",
    "        print(f\"Function '{func.__name__}' memory usage:\")\n",
    "        print(f\"Before: {before_memory} MB\")\n",
    "        print(f\"After: {after_memory} MB\")\n",
    "        print(f\"Memory increase: {after_memory - before_memory} B\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05c48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove later\n",
    "sys.argv[0] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34efd20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run_hyperparameters\n",
    "training_run = int(sys.argv[0])\n",
    "neuron_count=300\n",
    "connection_probability_dropoff=3\n",
    "connection_probability_scalar=0.00003\n",
    "input_layer_connectivity_multiplyer=50\n",
    "output_layer_connectivity_multiplyer=20\n",
    "weight_initialisation_range=2\n",
    "distances_from_input_output_layer_to_main_neuron_field=0.1\n",
    "hidden_neuron_connections = 7\n",
    "input_neuron_connections = 10\n",
    "output_neuron_connections = 10\n",
    "inference_steps = 8\n",
    "\n",
    "n_closes_neurons_connection_probability=\"connection_prob\"  #\"connection_prob\" /\"n_closest\"\n",
    "activation_function=\"sigmoid\" #relu\n",
    "\n",
    "generation_size=10\n",
    "n_survivors=3\n",
    "mutation_range=0.1\n",
    "training_set_size=1000\n",
    "mutation_range_reducing_interval=\"none\"\n",
    "mutation_range_reducing_factor=\"none\"\n",
    "\n",
    "reducing_mutaiton_range=\"no\"\n",
    "stochastic_mutation_range=\"yes\"\n",
    "multiple_training_sets=\"yes\"\n",
    "keep_best_of_n_generations_keep_n_best=\"keep_n_best\"\n",
    "allow_topological_modification=\"no\"\n",
    "non_uniform_distribution_in_stochastic_mutation_range=\"no\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d09810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function produces a configuration of parameters based on an input number. this allows the python script to be run with just one parameter instead of 8\n",
    "\n",
    "def get_configuration(index):\n",
    "    base_config = {\n",
    "        \"neuron_count\": 1000,\n",
    "        \"connection_probability_dropoff\": 3.0,\n",
    "        \"hidden_neuron_connections\": 6,\n",
    "        \"inference_steps\": 8,\n",
    "        \"n_survivors\": 3,\n",
    "        \"activation_function\": \"leaky_relu\",\n",
    "    }\n",
    "\n",
    "    params_to_evaluate = list(base_config.keys())\n",
    "    param_index = index // 5\n",
    "    run_index = index % 5\n",
    "\n",
    "    param = params_to_evaluate[param_index]\n",
    "\n",
    "    if param == \"neuron_count\":\n",
    "        base_config[param] = int((np.linspace(9, 19, 5) ** 2.5)[run_index])\n",
    "    elif param == \"connection_probability_dropoff\":\n",
    "        base_config[param] = np.linspace(1, 4, 5)[run_index]\n",
    "    elif param == \"hidden_neuron_connections\":\n",
    "        base_config[param] = int(np.linspace(20, 40, 5)[run_index])\n",
    "        base_config[\"n_closes_neurons_connection_probability\"] = \"n_closest\"\n",
    "    elif param == \"inference_steps\":\n",
    "        base_config[param] = int(np.linspace(6, 20, 5)[run_index])\n",
    "    elif param == \"n_survivors\":\n",
    "        base_config[param] = int(np.linspace(1, 12, 5)[run_index])\n",
    "    elif param == \"activation_function\":\n",
    "        options = [\"relu\", \"leaky_relu\"]\n",
    "        base_config[param] = options[run_index % len(options)]\n",
    "\n",
    "    return base_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01a6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {         \"training_run\":training_run,\n",
    "                   \"neuron_count\":neuron_count,\n",
    "                   \"connection_probability_dropoff\":connection_probability_dropoff,\n",
    "                   \"connection_probability_scalar\":connection_probability_scalar,\n",
    "                   \"input_layer_connectivity_multiplyer\":input_layer_connectivity_multiplyer,\n",
    "                   \"output_layer_connectivity_multiplyer\":output_layer_connectivity_multiplyer,\n",
    "                   \"weight_initialisation_range\":weight_initialisation_range,\n",
    "                   \"n_closes_neurons_connection_probability\":n_closes_neurons_connection_probability,\n",
    "                   \"hidden_neuron_connections\" : hidden_neuron_connections,\n",
    "                   \"input_neuron_connections\" : input_neuron_connections,\n",
    "                   \"output_neuron_connections\" : output_neuron_connections,\n",
    "                   \"inference_steps\" : inference_steps,\n",
    "                   \"activation_function\":activation_function,\n",
    "                   \"generation_size\":generation_size,\n",
    "                   \"n_survivors\":n_survivors,\n",
    "                   \"mutation_range\":mutation_range,\n",
    "                   \"training_set_size\":training_set_size,\n",
    "                   \"mutation_range_reducing_interval\":mutation_range_reducing_interval,\n",
    "                   \"mutation_range_reducing_factor\":mutation_range_reducing_factor,\n",
    "                   \"reducing_mutaiton_range\":reducing_mutaiton_range,\n",
    "                   \"stochastic_mutation_range\":stochastic_mutation_range,\n",
    "                   \"multiple_training_sets\":multiple_training_sets,\n",
    "                   \"allow_topological_modification\":allow_topological_modification\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc120fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_run : 1\n",
      "neuron_count : 448\n",
      "connection_probability_dropoff : 3.0\n",
      "connection_probability_scalar : 3e-05\n",
      "input_layer_connectivity_multiplyer : 50\n",
      "output_layer_connectivity_multiplyer : 20\n",
      "weight_initialisation_range : 2\n",
      "n_closes_neurons_connection_probability : connection_prob\n",
      "hidden_neuron_connections : 6\n",
      "input_neuron_connections : 10\n",
      "output_neuron_connections : 10\n",
      "inference_steps : 8\n",
      "activation_function : leaky_relu\n",
      "generation_size : 10\n",
      "n_survivors : 3\n",
      "mutation_range : 0.1\n",
      "training_set_size : 1000\n",
      "mutation_range_reducing_interval : none\n",
      "mutation_range_reducing_factor : none\n",
      "reducing_mutaiton_range : no\n",
      "stochastic_mutation_range : yes\n",
      "multiple_training_sets : yes\n",
      "allow_topological_modification : no\n"
     ]
    }
   ],
   "source": [
    "settings = get_configuration(int(sys.argv[0]))\n",
    "for i in settings.keys():\n",
    "    config[i]=settings[i]\n",
    "for i in config.keys():   \n",
    "    print(i,\":\",config[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2ce317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "def load_local_mnist_data(path):\n",
    "    with np.load(path) as f:\n",
    "        x_train, y_train = f['x_train'], f['y_train']\n",
    "        x_test, y_test = f['x_test'], f['y_test']\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "(train_X, train_y), (test_X, test_y) = load_local_mnist_data('mnist.npz')\n",
    "#one hot encode\n",
    "def one_hot_encode(x):\n",
    "    out = np.zeros((len(x), max(x)+1))\n",
    "    for i in range(len(x)):\n",
    "        out[i][x[i]] = 1\n",
    "    return out\n",
    "\n",
    "y_train_ohe = one_hot_encode(train_y)\n",
    "y_test_ohe = one_hot_encode(test_y)\n",
    "#flatten images\n",
    "x_train = train_X.reshape(len(train_X), 28*28)\n",
    "x_test = test_X.reshape(len(test_X), 28*28)\n",
    "\n",
    "x_test = np.array_split(x_test, 10)\n",
    "y_test_ohe = np.array_split(y_test_ohe, 10)\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train_ohe[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adbc8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population(population_size):\n",
    "    population = []\n",
    "    print(\"Creating networks\")\n",
    "    for i in range(population_size):\n",
    "        net = nlnn(output_neurons = 10, hidden_neurons = config[\"neuron_count\"])\n",
    "        if config[\"n_closes_neurons_connection_probability\"] == \"connection_prob\":\n",
    "            net.initialise_structure(connection_probability_dropoff=config[\"connection_probability_dropoff\"], connection_probabily_scalar=config[\"connection_probability_scalar\"], input_connection_prob_multiplyer = config[\"input_layer_connectivity_multiplyer\"], output_connection_prob_multiplyer = config[\"output_layer_connectivity_multiplyer\"])\n",
    "        elif config[\"n_closes_neurons_connection_probability\"] == \"n_closest\":\n",
    "            net.initialise_structure_n_closest(hidden_neuron_connections = config[\"hidden_neuron_connections\"], input_neuron_connections = config[\"input_neuron_connections\"], output_neuron_connections = config[\"output_neuron_connections\"])\n",
    "        #net.initialise_randomly()\n",
    "        population.append(net)\n",
    "        print(\"|\", end=\"\")\n",
    "\n",
    "    print(\"done!\")\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2db86197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf(t):\n",
    "        return t[0]\n",
    "\n",
    "#measure performance of all the networks\n",
    "def evaluate_performance(population, x, y):\n",
    "    performances = []\n",
    "    print(\"evaluating performances\", end=\"\")\n",
    "    for net in population:\n",
    "        predictions = net.predict(x, config[\"inference_steps\"])[0]\n",
    "        correct_count = len(x)-(np.sum(np.abs(y - predictions))/2)\n",
    "        performances.append((correct_count/len(x), net))\n",
    "        print(\"|\", end=\"\")\n",
    "    print(\" done!\", end=\" \")\n",
    "    #sort by best performance\n",
    "    performances.sort(key = get_perf, reverse = True)\n",
    "    return performances\n",
    "\n",
    "# Revised pseudo-code for the new version of the evaluate_performance function\n",
    "def evaluate_performance_parallel(population, x, y, config):\n",
    "    # Initialize neuron_values for all networks in the population\n",
    "    dim_matrix = population[0].dim_matrix  # Assuming all networks have the same dim_matrix\n",
    "    neuron_values = np.zeros((len(population), len(x), dim_matrix))\n",
    "    neuron_values[:, :, :x.shape[1]] = np.repeat(x[np.newaxis, :, :], len(population), axis=0)\n",
    "    \n",
    "    # Initialize performances list\n",
    "    performances = []\n",
    "    print(\"Evaluating performances in parallel\", end=\"\")\n",
    "    \n",
    "    # Propagation Steps\n",
    "    for step in range(config[\"inference_steps\"]):\n",
    "        # Batched Matrix Multiplication and Non-linearity (Leaky ReLU in this case)\n",
    "        z = np.matmul(neuron_values, np.array([net.adj_matrix for net in population]))  # Batched multiplication\n",
    "        z = np.where(z > 0, z, z * 0.01)  # Leaky ReLU\n",
    "        neuron_values[:, :, :x.shape[1]] = np.repeat(x[np.newaxis, :, :], len(population), axis=0)  # Update with x\n",
    "    \n",
    "    # Scoring\n",
    "    for i, net in enumerate(population):\n",
    "        individual_output = neuron_values[i]  # Replace with your method of extracting output\n",
    "        predictions = np.argmax(individual_output, axis=1)  # Your prediction logic here\n",
    "        predictions = np.eye(net.output_neurons)[predictions]\n",
    "        correct_count = len(x) - (np.sum(np.abs(y - predictions)) / 2)\n",
    "        performances.append((correct_count / len(x), net))\n",
    "        print(\"|\", end=\"\")\n",
    "    \n",
    "    print(\" done!\", end=\" \")\n",
    "    \n",
    "    # Sort by best performance\n",
    "    performances.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    return performances\n",
    "\n",
    "# Example usage (replace with your actual data and network objects)\n",
    "# evaluate_performance_parallel(population, x_test[test_set], y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa59dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repopulate(evaluated_networks, mutation_range, n):\n",
    "    offspring_per_network = int(population_size/n)\n",
    "    parents = [i[1] for i in evaluated_networks[:n]]\n",
    "    offspring = []\n",
    "    for net in parents:\n",
    "        net_offspring = net.reproduce(min(offspring_per_network, population_size - len(offspring)), mutation_range)\n",
    "        offspring.extend(net_offspring)\n",
    "    next_gen = parents + offspring\n",
    "    next_gen = next_gen[:population_size]\n",
    "    return next_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59dab4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_over_time = []\n",
    "test_sets_used = []\n",
    "mutation_ranges = []\n",
    "validation_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccf1b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks\n",
      "||||||||||done!\n",
      "evaluating performances|||||||||| done! best performer of this generation : 0.133\n"
     ]
    }
   ],
   "source": [
    "neuron_count = 200\n",
    "inference_steps = 3\n",
    "#Training loop\n",
    "    #loading hyperparameters\n",
    "n = config[\"n_survivors\"]\n",
    "mutation_range = config[\"mutation_range\"]\n",
    "population_size = config[\"generation_size\"]\n",
    "print_graphs = False\n",
    "population_size = 10\n",
    "\n",
    "networks = create_population(population_size)\n",
    "networks = evaluate_performance(networks, x_test[0], y_test_ohe[0])\n",
    "print(\"best performer of this generation :\", networks[0][0])\n",
    "performance_over_time.append(np.array(networks)[:,0])\n",
    "networks = repopulate(networks, mutation_range,n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c877d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 2  test set: 0 Evaluating performances in parallel"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 1242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m test_sets_used\u001b[38;5;241m.\u001b[39mappend(test_set)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m test set:\u001b[39m\u001b[38;5;124m\"\u001b[39m,test_set,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m networks \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_performance_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetworks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_ohe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m best:\u001b[39m\u001b[38;5;124m\"\u001b[39m, networks[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] )\u001b[38;5;66;03m#, \"second:\", evaluated_networks[1][0], \"third:\", evaluated_networks[2][0])\u001b[39;00m\n\u001b[1;32m     17\u001b[0m performance_over_time\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(networks)[:,\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[19], line 32\u001b[0m, in \u001b[0;36mevaluate_performance_parallel\u001b[0;34m(population, x, y, config)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Propagation Steps\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Batched Matrix Multiplication and Non-linearity (Leaky ReLU in this case)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneuron_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj_matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Batched multiplication\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(z \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, z, z \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m)  \u001b[38;5;66;03m# Leaky ReLU\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     neuron_values[:, :, :x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(x[np\u001b[38;5;241m.\u001b[39mnewaxis, :, :], \u001b[38;5;28mlen\u001b[39m(population), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Update with x\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 1242)"
     ]
    }
   ],
   "source": [
    "\n",
    "generations = 1000\n",
    "test_set = 0\n",
    "for gen in range(generations):\n",
    "    if(config[\"reducing_mutaiton_range\"]==\"yes\"):\n",
    "        if(gen%config[\"mutation_range_reducing_interval\"]==0 and gen!=0): \n",
    "            mutation_range/=config[\"mutation_range_reducing_factor\"]\n",
    "            print(\"decreasing mutation range from\",mutation_range*config[\"mutation_range_reducing_factor\"],\"to\",mutation_range)\n",
    "    print(\"generation \"+str(len(performance_over_time)+1), end=\" \")\n",
    "\n",
    "    if config[\"multiple_training_sets\"] == \"yes\"  and gen!=0:\n",
    "        test_set = np.random.randint(10)\n",
    "    test_sets_used.append(test_set)\n",
    "    print(\" test set:\",test_set,end=\" \")\n",
    "    networks = evaluate_performance_parallel(networks, x_test[test_set], y_test_ohe[test_set], config)\n",
    "    \n",
    "    print(\" best:\", networks[0][0] )#, \"second:\", evaluated_networks[1][0], \"third:\", evaluated_networks[2][0])\n",
    "    performance_over_time.append(np.array(networks)[:,0])\n",
    "    generational_mutation_range = mutation_range\n",
    "    if config[\"stochastic_mutation_range\"]==\"yes\": #change back\n",
    "        generational_mutation_range = np.random.rand() * mutation_range\n",
    "    mutation_ranges.append(generational_mutation_range)\n",
    "    print(\"mutating in range:\", generational_mutation_range)\n",
    "    networks = repopulate(networks, generational_mutation_range, config[\"n_survivors\"])\n",
    "    if(gen%10 == 0):\n",
    "        val_accuracy = evaluate_performance([networks[0]], x_val, y_val)[0][0]\n",
    "        validation_accuracy.append(val_accuracy)\n",
    "    if(gen%10==0):\n",
    "        plt.plot(np.array(performance_over_time), alpha= 0.1)\n",
    "        plt.plot(np.array(performance_over_time)[:,0])\n",
    "        plt.show()\n",
    "        print(\"average best of last 100 generations\",np.average(np.array(performance_over_time)[-100:,0]))  \n",
    "        plt.plot(validation_accuracy)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46dc167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising performance across the 10 different sets\n",
    "def visualise_performance():\n",
    "    performance_hist = np.array(performance_over_time)[-len(test_sets_used):,0]\n",
    "    set_perf = []\n",
    "    for i in range(10):\n",
    "        set_perf.append([])\n",
    "    for i in range(len(test_sets_used)-10):\n",
    "        set_perf[test_sets_used[i]].append(performance_hist[i])\n",
    "\n",
    "    for i in set_perf:\n",
    "        plt.plot(i, alpha=0.8)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    plt.violinplot(set_perf)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    performance_hist = np.array(performance_over_time)[-len(test_sets_used):]\n",
    "    performance_changes = []\n",
    "    for i in range(len(performance_hist)-1):\n",
    "        performance_changes.append(-(np.average(performance_hist[i])-np.average(performance_hist[i+1])))\n",
    "\n",
    "    plt.scatter(np.array(performance_changes)[:len(mutation_ranges)], np.array(mutation_ranges)[:len(performance_changes)])\n",
    "    plt.xlabel('change in perform')\n",
    "    plt.ylabel('Y-axis label')\n",
    "    plt.title(\"avg performance increase vs. mutation ranges\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.violinplot(np.array(mutation_ranges))\n",
    "    plt.title(\"frequency of mutation ranges\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(performance_over_time, alpha= 0.1)\n",
    "    plt.plot(np.array(performance_over_time)[:,0])\n",
    "    plt.title(\"performance of ranked individuals\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(np.average(np.split(np.array(performance_over_time)[:6400,0], 40),axis =1))\n",
    "    plt.title(\"performannce over time, smoothed\")\n",
    "    plt.show()\n",
    "    \n",
    "visualise_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1169d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"duration\"] = duration\n",
    "\n",
    "folder_name = 'run_'+str(training_run)\n",
    "suffix = 1\n",
    "\n",
    "while os.path.exists(folder_name):\n",
    "    suffix += 1\n",
    "    folder_name = f\"{folder_name}_{suffix}\"\n",
    "\n",
    "os.makedirs(folder_name)\n",
    "\n",
    "\n",
    "performance_over_time_array = np.array(performance_over_time)\n",
    "\n",
    "np.savetxt(folder_name+'/training_run_'+str(training_run)+'_performance.csv', performance_over_time_array, delimiter=',')\n",
    "np.savetxt(folder_name+'/training_run_'+str(training_run)+'_test_sets_used.csv', test_sets_used, delimiter=',')\n",
    "np.savetxt(folder_name+'/training_run_'+str(training_run)+'_mutation_ranges.csv', mutation_ranges, delimiter=',')\n",
    "np.savetxt(folder_name+'/training_run_'+str(training_run)+'_best_weights.csv', evaluated_networks[0][1].adj_matrix.toarray(), delimiter=',')\n",
    "np.save(folder_name+'/training_run_'+str(training_run)+'_config.npy', np.array(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd072ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de202d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
